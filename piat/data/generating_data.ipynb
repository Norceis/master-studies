{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-15T17:08:45.294722300Z",
     "start_time": "2023-08-15T17:08:45.269724Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai.error import ServiceUnavailableError, Timeout\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from data.openai_api_key import key\n",
    "\n",
    "path_to_dataset = pathlib.Path('./dataset')\n",
    "\n",
    "openai.api_key = key\n",
    "\n",
    "# prompt = (f\"Jesteś światowej sławy generatorem bajek dla dzieci o dowolnym temacie i treści o długości około 3000 słów. \"\n",
    "#           f\"Twoja odpowiedź powinna być w formacie JSON: {'title': 'tytuł bajki', 'content': 'treść bajki'}. \"\n",
    "#           f\"Twoja odpowiedź nie powinna zawierać żadnej innej treści oprócz JSON-a\")\n",
    "\n",
    "prompt = f\"Jesteś światowej sławy generatorem bajek dla dzieci w języku polskim o dowolnym temacie i treści o długości nie większej niż 2500 słów. Twoja odpowiedź nie powinna zawierać żadnej innej treści oprócz treści bajki.\"\n",
    "\n",
    "conversation_history = [\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [2:08:29<09:52, 59.27s/it]  "
     ]
    }
   ],
   "source": [
    "samples_to_generate = 200\n",
    "temperature = 1.0\n",
    "\n",
    "for _ in tqdm(range(samples_to_generate)):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation_history,\n",
    "        timeout=60,\n",
    "        temperature=temperature\n",
    "        )\n",
    "    except:\n",
    "        sleep(60)\n",
    "        continue\n",
    "    \n",
    "    response_metadata = {\n",
    "        \"id\": response['id'],\n",
    "        \"object\": response['object'],\n",
    "        \"created\": response['created'],\n",
    "        \"model\": response['model'],\n",
    "        \"usage\": response['usage'],\n",
    "        'temperature': temperature,\n",
    "        'prompt': prompt,\n",
    "        \"assistant_reply\": response['choices'][0]['message']['content']\n",
    "    }\n",
    "    \n",
    "    next_index = len(list(path_to_dataset.glob('*')))\n",
    "    content = response['choices'][0]['message']['content']\n",
    "    output_filename = f'{next_index}_{len(content)}_{str(temperature)}.json'\n",
    "\n",
    "    try:\n",
    "        with open(path_to_dataset / output_filename, 'w') as json_file:\n",
    "            json.dump(response_metadata, json_file, indent=4, ensure_ascii=False)\n",
    "            \n",
    "    except (UnicodeDecodeError, UnicodeEncodeError, JSONDecodeError):\n",
    "        with open(path_to_dataset / output_filename, 'w') as json_file:\n",
    "            json.dump(response_metadata, json_file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-14T06:37:02.119448200Z"
    }
   },
   "id": "e8f8dfaa441c9e4d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted dataset\\644_2484_0.8.json\n",
      "Sum of used tokens: 2536123\n",
      "Character count: 6145146\n"
     ]
    }
   ],
   "source": [
    "sum_used_tokens = 0\n",
    "character_count = 0\n",
    "\n",
    "for file_path in path_to_dataset.glob('*'):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            sum_used_tokens += json_data['usage']['total_tokens']\n",
    "            character_count += len(json_data['assistant_reply'])\n",
    "            \n",
    "    except JSONDecodeError:\n",
    "        file_path.unlink()\n",
    "        print(f'Deleted {file_path}')\n",
    "\n",
    "print(f'Sum of used tokens: {sum_used_tokens}\\nCharacter count: {character_count}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T17:08:48.322122400Z",
     "start_time": "2023-08-15T17:08:47.549116800Z"
    }
   },
   "id": "d64343cc0da3de07"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51d5d6b3c68d0176"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# for filepath in path_to_metadata.iterdir():\n",
    "#     if filepath.suffix == '.json':  # Change this condition to match your file type\n",
    "#         if str(filepath)[-8:] == '0.9.json':\n",
    "# \n",
    "#             parts = str(filepath.name).split('_')\n",
    "#             joined_name = f'{parts[0]}_{parts[-2]}_{parts[-1]}'\n",
    "#             \n",
    "#             new_filename = filepath.name.replace(filepath.name, joined_name)  \n",
    "#             new_path = filepath.with_name(new_filename)\n",
    "#             \n",
    "#             filepath.rename(new_path)\n",
    "#             print(f'Renamed {filepath.name} to {new_filename}')\n",
    "#             \n",
    "#         else:\n",
    "#             \n",
    "#             parts = str(filepath.name).split('_')\n",
    "#             joined_name = f'{parts[0]}_{parts[-1][:-5]}_0.8.json'\n",
    "#             \n",
    "#             new_filename = filepath.name.replace(filepath.name, joined_name)  \n",
    "#             new_path = filepath.with_name(new_filename)\n",
    "#             \n",
    "#             filepath.rename(new_path)\n",
    "#             print(f'Renamed {filepath.name} to {new_filename}')\n",
    "#             \n",
    "#             \n",
    "#             \n",
    "# for filepath in path_to_raw_data.iterdir():\n",
    "#     if filepath.suffix == '.json':  # Change this condition to match your file type\n",
    "#         if str(filepath)[-8:] == '0.9.json':\n",
    "# \n",
    "#             parts = str(filepath.name).split('_')\n",
    "#             joined_name = f'{parts[0]}_{parts[-2]}_{parts[-1]}'\n",
    "#             \n",
    "#             new_filename = filepath.name.replace(filepath.name, joined_name)  \n",
    "#             new_path = filepath.with_name(new_filename)\n",
    "#             \n",
    "#             filepath.rename(new_path)\n",
    "#             print(f'Renamed {filepath.name} to {new_filename}')\n",
    "#             \n",
    "#         else:\n",
    "#             \n",
    "#             parts = str(filepath.name).split('_')\n",
    "#             joined_name = f'{parts[0]}_{parts[-1][:-5]}_0.8.json'\n",
    "#             \n",
    "#             new_filename = filepath.name.replace(filepath.name, joined_name)  \n",
    "#             new_path = filepath.with_name(new_filename)\n",
    "#             \n",
    "#             filepath.rename(new_path)\n",
    "#             print(f'Renamed {filepath.name} to {new_filename}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T12:08:43.035456600Z",
     "start_time": "2023-08-13T12:08:43.022457400Z"
    }
   },
   "id": "b8063fc22db28667"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cbe390edc8a6fb89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
