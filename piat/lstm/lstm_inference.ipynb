{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:18:51.650212600Z",
     "start_time": "2023-09-07T15:18:51.635217800Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('./models/1/vocab.json', 'r') as file:\n",
    "    vocab = json.load(file)\n",
    "\n",
    "with open('./models/1/reverse_vocab.json', 'r') as file:\n",
    "    reverse_vocab = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:18:52.099326400Z",
     "start_time": "2023-09-07T15:18:52.059327800Z"
    }
   },
   "id": "972b3a51c84d45f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "MyLSTM(\n  (decoder): Decoder(\n    (dropout_layer): Dropout(p=0.1, inplace=False)\n    (embedding_layer): Embedding(22231, 300)\n    (lstm_layer): LSTM(300, 1024, num_layers=2, dropout=0.1)\n    (fc): Linear(in_features=1024, out_features=22231, bias=True)\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.data_processing import preprocess_and_encode_string\n",
    "\n",
    "converted_text = preprocess_and_encode_string('dawno dawno temu za górami za lasami', vocab)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(f'./models/1/model_after_30_epoch.pth')\n",
    "model.eval()\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:20:34.148278300Z",
     "start_time": "2023-09-07T15:20:33.869222100Z"
    }
   },
   "id": "fac45278fdf36e81"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          3,   5,   5,   6, 153,  26, 153,  26], device='cuda:0') tensor([18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062,\n",
      "        18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062,\n",
      "        18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062,\n",
      "        18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062,\n",
      "        18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062, 18.0062,\n",
      "        18.0062, 18.0062,  5.9264, 11.2564, 11.2564, 10.8817,  9.0546,  9.2523,\n",
      "         9.0546,  9.2618], device='cuda:0', grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import pad_zeros\n",
    "\n",
    "input_data = pad_zeros(converted_text[:-1], 50, front=True)\n",
    "\n",
    "input_tensor = torch.tensor([input_data], dtype=torch.long)\n",
    "# print(input_tensor.shape)\n",
    "input_tensor = input_tensor.to(device)\n",
    "output = model.decoder(input_tensor[-1])\n",
    "# output = output[1:].reshape(-1, output.shape[2])\n",
    "# output.argmax(1)\n",
    "argmax_values, argmax_indices = torch.max(output, dim=-1)\n",
    "print(argmax_indices, argmax_values)\n",
    "fairytale.append(argmax_indices.tolist()[0][len_input_data - 1])\n",
    "# argmax_indices, argmax_values\n",
    "# decoded_sentence = decode_string(argmax_indices.tolist()[0], reverse_vocab)\n",
    "# ' '.join(decoded_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:24:14.706076Z",
     "start_time": "2023-09-07T15:24:14.527164500Z"
    }
   },
   "id": "b04a6cba021369d8"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dawno dawno temu za górami za lasami.  I dawno pomoc to do po był po.  Się w był i że swojego bardzo Do sobie w i swojego. .  Był Po kilku minutach dotarli wielu przyjaciół i nie jest dla Na to że że w Się że jest to się w lesie i.  Od tamtego dnia w i tak dzięki swojej wioski zaczęli tańczyć w.  I się Po całym królestwie zwierząt a potem wieść w magicznym lesie. . . .  W Się do lasu który uwielbiał spędzać czas na skraju lasu mieszkał w którym zawsze miał swoje marzenia mogą być.  W którym wszyscy byli się że.  Był w końcu gdy jednej chwili pojawił się i tak więc na skraju lasu.  Na to w lesie i i.  I Pewnego pięknego letniego dnia.  I że to było tak dzięki nim.  Był I tak oto opowieść o przygodach.  W magicznym lesie.  i.  I. \n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import decode_string, postprocess_string\n",
    "from copy import deepcopy\n",
    "\n",
    "context_len = 50\n",
    "how_many_sentences = 20\n",
    "roulette = True\n",
    "\n",
    "fairytale = deepcopy(converted_text)\n",
    "# fairytale = [196, 1028,  389,  810, 1029,  170,  992,  131,   26, 1030,  305, 1031,\n",
    "#      984,    3,    2,  982, 1032,   62, 1033, 1034, 1035,   26,   58,    6,\n",
    "#      334,  883, 1027,    3,    2,  170, 1036,  193,   98,  908,   34, 1037,\n",
    "#     1038,  108,  578, 1021,    3,    2,  385,   76,    6,  533,  511, 1039,\n",
    "#      108, 1040,   44,  533, 1041,    3,    2, 1042, 1043, 1044,   26, 1045,\n",
    "#      415,  288,  403, 1046,  196,  425,   78, 1047,  108, 1048, 1049,  864,\n",
    "#     1050,   78,  108, 1051,    3,    2,  982,   61,   62, 1052, 1027,   26,\n",
    "#     1053,   62,  820,    3,    2, 1012, 1054,   26,   64, 1055, 1056,  236,\n",
    "#     1057,   31,  218]\n",
    "\n",
    "while True:\n",
    "    if how_many_sentences == fairytale.count(3):\n",
    "        break\n",
    "    if len(fairytale) > 500:\n",
    "        break\n",
    "\n",
    "    input_data = fairytale[-context_len:]\n",
    "    len_input_data = len(input_data)\n",
    "    if len(input_data) < context_len:\n",
    "        input_data = pad_zeros(input_data[:-1], context_len, front=True)\n",
    "\n",
    "    input_tensor = torch.tensor([input_data], dtype=torch.long)\n",
    "\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    output = model.decoder(input_tensor[-1])\n",
    "\n",
    "    argmax_values, argmax_indices = torch.max(output, dim=-1)\n",
    "\n",
    "    if roulette:\n",
    "        topk_values, topk_indices = torch.topk(output, k=10, dim=-1)\n",
    "        softmax_probs = torch.softmax(topk_values, dim=-1)\n",
    "        samples = torch.multinomial(softmax_probs, 1, replacement=True)\n",
    "        selected_indices = topk_indices.gather(1, samples)\n",
    "        fairytale.append(selected_indices.reshape((1, context_len)).tolist()[0][len_input_data - 1])\n",
    "    else:\n",
    "        argmax_values, argmax_indices = torch.max(output, dim=-1)\n",
    "        fairytale.append(argmax_indices.tolist()[len_input_data - 1])\n",
    "\n",
    "decoded_sentence = decode_string(fairytale, reverse_vocab)\n",
    "postprocessed_sentence = postprocess_string(decoded_sentence)\n",
    "print(postprocessed_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:33:22.768295300Z",
     "start_time": "2023-09-07T15:33:21.841960300Z"
    }
   },
   "id": "d1b74347dee43c2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e72e643234278625"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
