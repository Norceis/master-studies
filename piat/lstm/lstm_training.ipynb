{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from src.data_processing import load_processed_fairytales_dataset_for_lstm, save_experiment_input, shuffle\n",
    "from src.my_lstm import Decoder, MyLSTM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:39:03.713006700Z",
     "start_time": "2023-09-07T15:39:01.453239200Z"
    }
   },
   "id": "729a8a26fd818639"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 2124 files [00:00, 3933.35 files/s]\n",
      "Preprocessing: 100%|██████████| 10/10 [00:00<00:00, 2500.63it/s]\n",
      "Converting strings to integers: 100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "Generating encoded pairs: 100%|██████████| 10/10 [00:00<00:00, 5000.96it/s]\n"
     ]
    }
   ],
   "source": [
    "splitted_dataset, vocab, reverse_vocab = load_processed_fairytales_dataset_for_lstm(how_many=10, context_size=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:39:04.057002900Z",
     "start_time": "2023-09-07T15:39:03.379002500Z"
    }
   },
   "id": "da9ee7ea9da941a9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = torch.tensor(splitted_dataset, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:39:04.062003100Z",
     "start_time": "2023-09-07T15:39:03.958002600Z"
    }
   },
   "id": "f505e1a36751764f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully\n"
     ]
    }
   ],
   "source": [
    "experiment_number = 2  # experiment_number = get_next_folder_number(Path('./models'))\n",
    "save_experiment_input(dataset, dataset, vocab, reverse_vocab, experiment_number)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T15:39:04.063004Z",
     "start_time": "2023-09-07T15:39:03.974003800Z"
    }
   },
   "id": "77e1114cb97544d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-09-07T15:39:04.040002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning epoch: 1, average loss: 6.6287: 100%|██████████| 43/43 [00:10<00:00,  4.00it/s]\n",
      "Learning epoch: 2, average loss: 6.2939: 100%|██████████| 43/43 [00:10<00:00,  4.15it/s]\n",
      "Learning epoch: 3, average loss: 6.2423: 100%|██████████| 43/43 [00:10<00:00,  4.15it/s]\n",
      "Learning epoch: 4, average loss: 6.1981: 100%|██████████| 43/43 [00:10<00:00,  4.15it/s]\n",
      "Learning epoch: 5, average loss: 6.1603: 100%|██████████| 43/43 [00:10<00:00,  4.13it/s]\n",
      "Learning epoch: 6, average loss: 6.0965: 100%|██████████| 43/43 [00:10<00:00,  4.13it/s]\n",
      "Learning epoch: 7, average loss: 6.0457: 100%|██████████| 43/43 [00:10<00:00,  4.13it/s]\n",
      "Learning epoch: 8, average loss: 5.9098: 100%|██████████| 43/43 [00:10<00:00,  4.13it/s]\n",
      "Learning epoch: 9, average loss: 5.7047: 100%|██████████| 43/43 [00:10<00:00,  4.12it/s]\n",
      "Learning epoch: 10, average loss: 5.7123: 100%|██████████| 43/43 [00:10<00:00,  4.12it/s]\n",
      "Learning epoch: 11, average loss: 5.6160: 100%|██████████| 43/43 [00:10<00:00,  4.11it/s]\n",
      "Learning epoch: 12, average loss: 5.5118: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 13, average loss: 5.5861: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 14, average loss: 5.4508: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 15, average loss: 5.5605: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 16, average loss: 5.5019: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 17, average loss: 5.4809: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 18, average loss: 5.6107: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 19, average loss: 5.4788: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 20, average loss: 5.4738: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 21, average loss: 5.5082: 100%|██████████| 43/43 [00:10<00:00,  4.09it/s]\n",
      "Learning epoch: 22, average loss: 5.4798: 100%|██████████| 43/43 [00:10<00:00,  4.08it/s]\n",
      "Learning epoch: 23, average loss: 5.3845: 100%|██████████| 43/43 [00:10<00:00,  4.09it/s]\n",
      "Learning epoch: 24, average loss: 5.4717: 100%|██████████| 43/43 [00:10<00:00,  4.09it/s]\n",
      "Learning epoch: 25, average loss: 5.4958: 100%|██████████| 43/43 [00:10<00:00,  4.09it/s]\n",
      "Learning epoch: 26, average loss: 5.4886: 100%|██████████| 43/43 [00:10<00:00,  4.09it/s]\n",
      "Learning epoch: 27, average loss: 5.4260: 100%|██████████| 43/43 [00:10<00:00,  4.10it/s]\n",
      "Learning epoch: 28, average loss: 5.4831: 100%|██████████| 43/43 [00:10<00:00,  4.09it/s]\n",
      "Learning epoch: 29, average loss: 5.3618: 100%|██████████| 43/43 [00:10<00:00,  4.09it/s]\n",
      "Learning epoch: 30, average loss: 5.5560: 100%|██████████| 43/43 [00:10<00:00,  4.08it/s]\n",
      "Learning epoch: 31, average loss: 5.4224: 100%|██████████| 43/43 [00:10<00:00,  4.07it/s]\n",
      "Learning epoch: 32, average loss: 5.3731: 100%|██████████| 43/43 [00:10<00:00,  4.04it/s]\n",
      "Learning epoch: 33, average loss: 5.4246: 100%|██████████| 43/43 [00:10<00:00,  3.95it/s]\n",
      "Learning epoch: 34, average loss: 5.5689: 100%|██████████| 43/43 [00:10<00:00,  3.95it/s]\n",
      "Learning epoch: 35, average loss: 5.4477: 100%|██████████| 43/43 [00:10<00:00,  4.04it/s]\n",
      "Learning epoch: 36, average loss: 5.4086: 100%|██████████| 43/43 [00:10<00:00,  4.04it/s]\n",
      "Learning epoch: 37, average loss: 5.3660: 100%|██████████| 43/43 [00:10<00:00,  4.05it/s]\n",
      "Learning epoch: 38, average loss: 5.4848: 100%|██████████| 43/43 [00:10<00:00,  4.05it/s]\n",
      "Learning epoch: 39, average loss: 5.4277: 100%|██████████| 43/43 [00:10<00:00,  4.05it/s]\n",
      "Learning epoch: 40, average loss: 5.4215: 100%|██████████| 43/43 [00:10<00:00,  4.05it/s]\n",
      "Learning epoch: 41, average loss: 5.4762: 100%|██████████| 43/43 [00:10<00:00,  4.05it/s]\n",
      "Learning epoch: 42, average loss: 5.3412: 100%|██████████| 43/43 [00:10<00:00,  4.05it/s]\n",
      "Learning epoch: 43, average loss: 5.3787: 100%|██████████| 43/43 [00:10<00:00,  4.05it/s]\n",
      "Learning epoch: 44, average loss: 5.4593: 100%|██████████| 43/43 [00:10<00:00,  4.00it/s]\n",
      "Learning epoch: 45, average loss: 5.3956: 100%|██████████| 43/43 [00:10<00:00,  4.01it/s]\n",
      "Learning epoch: 46, average loss: 5.4022: 100%|██████████| 43/43 [00:10<00:00,  3.94it/s]\n",
      "Learning epoch: 47, average loss: 5.4204: 100%|██████████| 43/43 [00:11<00:00,  3.90it/s]\n",
      "Learning epoch: 48, average loss: 5.3643: 100%|██████████| 43/43 [00:11<00:00,  3.84it/s]\n",
      "Learning epoch: 49, average loss: 5.3733: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 50, average loss: 5.3718: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 51, average loss: 5.3728: 100%|██████████| 43/43 [00:11<00:00,  3.82it/s]\n",
      "Learning epoch: 52, average loss: 5.5060: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 53, average loss: 5.3331: 100%|██████████| 43/43 [00:11<00:00,  3.82it/s]\n",
      "Learning epoch: 54, average loss: 5.4367: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 55, average loss: 5.3942: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 56, average loss: 5.4126: 100%|██████████| 43/43 [00:11<00:00,  3.80it/s]\n",
      "Learning epoch: 57, average loss: 5.3803: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 58, average loss: 5.3099: 100%|██████████| 43/43 [00:11<00:00,  3.82it/s]\n",
      "Learning epoch: 59, average loss: 5.3772: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 60, average loss: 5.4772: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 61, average loss: 5.4160: 100%|██████████| 43/43 [00:11<00:00,  3.82it/s]\n",
      "Learning epoch: 62, average loss: 5.4136: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 63, average loss: 5.3996: 100%|██████████| 43/43 [00:11<00:00,  3.82it/s]\n",
      "Learning epoch: 64, average loss: 5.4161: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 65, average loss: 5.4160: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 66, average loss: 5.4643: 100%|██████████| 43/43 [00:11<00:00,  3.72it/s]\n",
      "Learning epoch: 67, average loss: 5.4184: 100%|██████████| 43/43 [00:11<00:00,  3.71it/s]\n",
      "Learning epoch: 68, average loss: 5.4410: 100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "Learning epoch: 69, average loss: 5.3630: 100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "Learning epoch: 70, average loss: 5.3372: 100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "Learning epoch: 71, average loss: 5.3317: 100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "Learning epoch: 72, average loss: 5.3227: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 73, average loss: 5.5512: 100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "Learning epoch: 74, average loss: 5.4029: 100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "Learning epoch: 75, average loss: 5.3501: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 76, average loss: 5.3599: 100%|██████████| 43/43 [00:10<00:00,  3.91it/s]\n",
      "Learning epoch: 77, average loss: 5.4127: 100%|██████████| 43/43 [00:10<00:00,  3.95it/s]\n",
      "Learning epoch: 78, average loss: 5.4281: 100%|██████████| 43/43 [00:11<00:00,  3.82it/s]\n",
      "Learning epoch: 79, average loss: 5.3963: 100%|██████████| 43/43 [00:11<00:00,  3.80it/s]\n",
      "Learning epoch: 80, average loss: 5.4167: 100%|██████████| 43/43 [00:11<00:00,  3.89it/s]\n",
      "Learning epoch: 81, average loss: 5.4452: 100%|██████████| 43/43 [00:11<00:00,  3.88it/s]\n",
      "Learning epoch: 82, average loss: 5.4098: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 83, average loss: 5.4539: 100%|██████████| 43/43 [00:11<00:00,  3.78it/s]\n",
      "Learning epoch: 84, average loss: 5.3376: 100%|██████████| 43/43 [00:11<00:00,  3.81it/s]\n",
      "Learning epoch: 85, average loss: 5.4265: 100%|██████████| 43/43 [00:10<00:00,  3.94it/s]\n",
      "Learning epoch: 86, average loss: 5.3765: 100%|██████████| 43/43 [00:11<00:00,  3.87it/s]\n",
      "Learning epoch: 87, average loss: 5.3504: 100%|██████████| 43/43 [00:11<00:00,  3.90it/s]\n",
      "Learning epoch: 88, average loss: 5.3394: 100%|██████████| 43/43 [00:10<00:00,  3.92it/s]\n",
      "Learning epoch: 89, average loss: 5.3858: 100%|██████████| 43/43 [00:11<00:00,  3.76it/s]\n",
      "Learning epoch: 90, average loss: 5.4283: 100%|██████████| 43/43 [00:11<00:00,  3.69it/s]\n",
      "Learning epoch: 91, average loss: 5.3957: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 92, average loss: 5.4559: 100%|██████████| 43/43 [00:11<00:00,  3.67it/s]\n",
      "Learning epoch: 93, average loss: 5.4460: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 94, average loss: 5.3962: 100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "Learning epoch: 95, average loss: 5.3598: 100%|██████████| 43/43 [00:11<00:00,  3.79it/s]\n",
      "Learning epoch: 96, average loss: 5.3209: 100%|██████████| 43/43 [00:11<00:00,  3.75it/s]\n",
      "Learning epoch: 97, average loss: 5.4308: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 98, average loss: 5.4229: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 99, average loss: 5.4294: 100%|██████████| 43/43 [00:11<00:00,  3.72it/s]\n",
      "Learning epoch: 100, average loss: 5.3874: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 101, average loss: 5.4728: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 102, average loss: 5.4363: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 103, average loss: 5.3881: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 104, average loss: 5.4236: 100%|██████████| 43/43 [00:11<00:00,  3.72it/s]\n",
      "Learning epoch: 105, average loss: 5.3574: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 106, average loss: 5.4249: 100%|██████████| 43/43 [00:11<00:00,  3.73it/s]\n",
      "Learning epoch: 107, average loss: 5.3371: 100%|██████████| 43/43 [00:11<00:00,  3.72it/s]\n",
      "Learning epoch: 108, average loss: 5.3957: 100%|██████████| 43/43 [00:11<00:00,  3.65it/s]\n",
      "Learning epoch: 109, average loss: 5.2890: 100%|██████████| 43/43 [00:11<00:00,  3.69it/s]\n",
      "Learning epoch: 110, average loss: 5.4479: 100%|██████████| 43/43 [00:11<00:00,  3.70it/s]\n",
      "Learning epoch: 111, average loss: 5.3033: 100%|██████████| 43/43 [00:11<00:00,  3.71it/s]\n",
      "Learning epoch: 112, average loss: 5.3595: 100%|██████████| 43/43 [00:11<00:00,  3.71it/s]\n",
      "Learning epoch: 113, average loss: 5.3587: 100%|██████████| 43/43 [00:11<00:00,  3.62it/s]\n",
      "Learning epoch: 114, average loss: 5.2667: 100%|██████████| 43/43 [00:11<00:00,  3.69it/s]\n",
      "Learning epoch: 115, average loss: 5.4610: 100%|██████████| 43/43 [00:11<00:00,  3.68it/s]\n",
      "Learning epoch: 116, average loss: 5.4517: 100%|██████████| 43/43 [00:11<00:00,  3.68it/s]\n",
      "Learning epoch: 117, average loss: 5.4182: 100%|██████████| 43/43 [00:11<00:00,  3.69it/s]\n",
      "Learning epoch: 118, average loss: 5.4100: 100%|██████████| 43/43 [00:11<00:00,  3.69it/s]\n",
      "Learning epoch: 119, average loss: 5.3202: 100%|██████████| 43/43 [00:11<00:00,  3.72it/s]\n",
      "Learning epoch: 120, average loss: 5.3864: 100%|██████████| 43/43 [00:11<00:00,  3.69it/s]\n",
      "Learning epoch: 121, average loss: 5.3792: 100%|██████████| 43/43 [00:11<00:00,  3.64it/s]\n",
      "Learning epoch: 122, average loss: 5.3935: 100%|██████████| 43/43 [00:11<00:00,  3.71it/s]\n",
      "Learning epoch: 123, average loss: 5.3877: 100%|██████████| 43/43 [00:11<00:00,  3.67it/s]\n",
      "Learning epoch: 124, average loss: 5.3149: 100%|██████████| 43/43 [00:11<00:00,  3.67it/s]\n",
      "Learning epoch: 125, average loss: 5.3439: 100%|██████████| 43/43 [00:11<00:00,  3.78it/s]\n",
      "Learning epoch: 126, average loss: 5.4319: 100%|██████████| 43/43 [00:11<00:00,  3.79it/s]\n",
      "Learning epoch: 127, average loss: 5.4211: 100%|██████████| 43/43 [00:11<00:00,  3.80it/s]\n",
      "Learning epoch: 128, average loss: 5.3673: 100%|██████████| 43/43 [00:11<00:00,  3.85it/s]\n",
      "Learning epoch: 129, average loss: 5.3930: 100%|██████████| 43/43 [00:11<00:00,  3.86it/s]\n",
      "Learning epoch: 130, average loss: 5.3724:  88%|████████▊ | 38/43 [00:09<00:01,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size_decoder = len(vocab)\n",
    "output_size = len(vocab)\n",
    "\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "dec_dropout = 0.1\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = MyLSTM(decoder_net, vocab_size=len(vocab)).to(device)\n",
    "# model = decoder_net\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, eps=1e-9)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    \n",
    "    p_bar = tqdm(range(0, len(dataset), batch_size), desc=f\"Learning epoch: {epoch}\")\n",
    "    dataset, _ = shuffle(dataset, dataset)\n",
    "    \n",
    "    average_loss_in_epoch = 0\n",
    "    for batch in p_bar:\n",
    "\n",
    "        src_batch = dataset[batch:batch + batch_size].to(device)\n",
    "        src_batch = src_batch.T\n",
    "    \n",
    "        output = model(src_batch)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        src_batch = src_batch[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, src_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        average_loss_in_epoch += loss.item()\n",
    "        p_bar.set_description(\n",
    "            desc=f\"Learning epoch: {epoch}, average loss: {average_loss_in_epoch / ((batch // batch_size) + 1 ):.4f}\")\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "    if not epoch % 50:\n",
    "        torch.save(model, f'./models/{experiment_number}/model_after_{epoch}_epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_path = f'./models/{experiment_number}/training_losses.txt'\n",
    "with open(loss_path, 'w') as file:\n",
    "    for loss in losses:\n",
    "        file.write(str(loss) + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2b6f2cc6c92530e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'x': range(len(losses)),\n",
    "                     'y': losses})\n",
    "\n",
    "fig = px.line(data, x='x', y='y', title='Line Plot Example')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af7bf22d60206867"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6c49176433565ca0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
